{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face Recognition and Drowsiness Detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1NXTbuWtJnmv9NUJfrDzPgMrrAeSYU2Pn",
      "authorship_tag": "ABX9TyOe6KsDb5KCa/14K1zSCmQA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Selva-Subramanian/FaceRecognition-DrowsinessDetection/blob/main/Face_Recognition_and_Drowsiness_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <b> Project Introduction"
      ],
      "metadata": {
        "id": "WxxW8xJ7abRK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Indian education landscape has been undergoing rapid changes for the past 10 years owing to the advancement of web-based learning services, specifically, eLearning platforms.\n",
        "#### Global E-learning is estimated to witness an 8X over the next 5 years to reach USD 2B in 2021. India is expected to grow with a CAGR of 44% crossing the 10M users mark in 2021. Although the market is growing on a rapid scale, there are major challenges associated with digital learning when compared with brick and mortar classrooms. One of many challenges is how to ensure quality learning for students. Digital platforms might overpower physical classrooms in terms of content quality but when it comes to understanding whether students are able to grasp the content in a live class scenario is yet an open-end challenge.\n",
        "#### In a physical classroom during a lecturing teacher can see the faces and assess the emotion of the class and tune their lecture accordingly, whether he is going fast or slow. He can identify students who need special attention. Digital classrooms are conducted via video telephony software program (ex-Zoom) where it’s not possible for medium scale class (25-50) to see all students and access the mood. Because of this drawback, students are not focusing on content due to lack of surveillance.\n",
        "#### While digital platforms have limitations in terms of physical surveillance but it comes with the power of data and machines which can work for you. It provides data in the form of video, audio, and texts which can be analysed using deep learning algorithms. Deep learning backed system not only solves the surveillance issue, but it also removes the human bias from the system, and all information is no longer in the teacher’s brain rather translated in numbers that can be analysed and tracked."
      ],
      "metadata": {
        "id": "bZ7ohZAbZUO1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <b> Problem Statement"
      ],
      "metadata": {
        "id": "lT4nQlSJak6F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### We will solve the above-mentioned challenge by applying deep learning algorithms to live video data. The solution to this problem is by recognizing the face, mark the attendance, log the individual’s session time and put a drowsiness alert.\n",
        "\n",
        "#### **Face Recognition**\n",
        "####This is a few shot learning live face attendance systems. The model should be able to real-time identify attending students in the live class based on few images of students.\n",
        "\n",
        "#### **Drowsiness Detector**\n",
        "#### This will detect facial landmarks and extract the eye regions. The algorithm should be able to identify students who are not attentive and drowsing in the class."
      ],
      "metadata": {
        "id": "dF3eB24calGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hKKRyEl0fCN",
        "outputId": "1f1b89cf-0182-4f3e-d6a2-8affcfbe5ec9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install tensorflow tensorflow-gpu opencv-python "
      ],
      "metadata": {
        "id": "ZIODtIQ1cYao",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35cb4c71-b895-438b-85fb-500900dc19f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Collecting tensorflow-gpu\n",
            "  Downloading tensorflow_gpu-2.8.0-cp37-cp37m-manylinux2010_x86_64.whl (497.5 MB)\n",
            "\u001b[K     |██████▊                         | 104.6 MB 1.5 MB/s eta 0:04:30\u001b[31mERROR: Exception:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 180, in _main\n",
            "    status = self.run(options, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/req_command.py\", line 199, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/commands/install.py\", line 319, in run\n",
            "    reqs, check_supported_wheels=not options.target_dir\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 128, in resolve\n",
            "    requirements, max_rounds=try_to_avoid_resolution_too_deep\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 473, in resolve\n",
            "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 341, in resolve\n",
            "    name, crit = self._merge_into_criterion(r, parent=None)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 172, in _merge_into_criterion\n",
            "    if not criterion.candidates:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/resolvelib/structs.py\", line 139, in __bool__\n",
            "    return bool(self._sequence)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 143, in __bool__\n",
            "    return any(self)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 129, in <genexpr>\n",
            "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 33, in _iter_built\n",
            "    candidate = func()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 205, in _make_candidate_from_link\n",
            "    version=version,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 312, in __init__\n",
            "    version=version,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 151, in __init__\n",
            "    self.dist = self._prepare()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 234, in _prepare\n",
            "    dist = self._prepare_distribution()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 318, in _prepare_distribution\n",
            "    self._ireq, parallel_builds=True\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/operations/prepare.py\", line 508, in prepare_linked_requirement\n",
            "    return self._prepare_linked_requirement(req, parallel_builds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/operations/prepare.py\", line 552, in _prepare_linked_requirement\n",
            "    self.download_dir, hashes\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/operations/prepare.py\", line 243, in unpack_url\n",
            "    hashes=hashes,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/operations/prepare.py\", line 102, in get_http_url\n",
            "    from_path, content_type = download(link, temp_dir.path)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/network/download.py\", line 157, in __call__\n",
            "    for chunk in chunks:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/progress_bars.py\", line 156, in iter\n",
            "    self.next(len(x))  # noqa: B305\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/progress/__init__.py\", line 120, in next\n",
            "    self.update()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/progress/bar.py\", line 83, in update\n",
            "    self.writeln(line)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/progress/__init__.py\", line 101, in writeln\n",
            "    self.clearln()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/progress/__init__.py\", line 90, in clearln\n",
            "    print('\\r\\x1b[K', end='', file=self.file)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/progress_bars.py\", line 106, in handle_sigint\n",
            "    self.finish()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/progress_bars.py\", line 96, in finish\n",
            "    super().finish()  # type: ignore\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/progress/__init__.py\", line 107, in finish\n",
            "    print(file=self.file)\n",
            "RuntimeError: reentrant call inside <_io.BufferedWriter name='<stdout>'>\u001b[0m\n",
            "\u001b[K"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os \n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.models import Model\n",
        "from keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten"
      ],
      "metadata": {
        "id": "rDVK9-nocYdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus: \n",
        "    tf.config.experimental.set_memory_growth(gpu, True)"
      ],
      "metadata": {
        "id": "OK8SsH0wcYf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move LFW Images to the following repository data/negative\n",
        "for directory in os.listdir('/content/drive/MyDrive/Colab Notebooks/AlmaBetter Notebooks/Capstone projects/Face Recognition and Drowsiness Detection - Selva Subramanian S/Dataset/lfw.tgz (Unzipped Files)/lfw'):\n",
        "    for file in os.listdir(os.path.join('/content/drive/MyDrive/Colab Notebooks/AlmaBetter Notebooks/Capstone projects/Face Recognition and Drowsiness Detection - Selva Subramanian S/Dataset/lfw.tgz (Unzipped Files)/lfw', directory)):\n",
        "        EX_PATH = os.path.join('/content/drive/MyDrive/Colab Notebooks/AlmaBetter Notebooks/Capstone projects/Face Recognition and Drowsiness Detection - Selva Subramanian S/Dataset/lfw.tgz (Unzipped Files)/lfw', directory, file)\n",
        "        NEW_PATH = os.path.join('/content/drive/MyDrive/Colab Notebooks/AlmaBetter Notebooks/Capstone projects/Face Recognition and Drowsiness Detection - Selva Subramanian S/Dataset/Negative', file)\n",
        "        os.replace(EX_PATH, NEW_PATH)"
      ],
      "metadata": {
        "id": "B_9YK6God2_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use uuid library to generate unique image names in Anchor\n",
        "import uuid\n",
        "os.path.join('/content/drive/MyDrive/Colab Notebooks/AlmaBetter Notebooks/Capstone projects/Face Recognition and Drowsiness Detection - Selva Subramanian S/Dataset/Anchor', '{}.jpg'.format(uuid.uuid1()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "ncAJPmwdd28l",
        "outputId": "8821dd31-38bb-40c6-8209-d36a656f1763"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks/AlmaBetter Notebooks/Capstone projects/Face Recognition and Drowsiness Detection - Selva Subramanian S/Dataset/Anchor/b3a23aa0-a211-11ec-ae50-0242ac1c0002.jpg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Establish a connection to the webcam\n",
        "cap = cv2.VideoCapture()\n",
        "while cap.isOpened(): \n",
        "    ret, frame = cap.read()\n",
        "   \n",
        "    # Cut down frame to 250x250px\n",
        "    frame = frame[120:120+250,200:200+250, :]\n",
        "    \n",
        "    # Collect anchors \n",
        "    if cv2.waitKey(1) & 0XFF == ord('a'):\n",
        "        # Create the unique file path \n",
        "        imgname = os.path.join('/content/drive/MyDrive/Colab Notebooks/AlmaBetter Notebooks/Capstone projects/Face Recognition and Drowsiness Detection - Selva Subramanian S/Dataset/Anchor', '{}.jpg'.format(uuid.uuid1()))\n",
        "        # Write out anchor image\n",
        "        cv2.imwrite(imgname, frame)\n",
        "    \n",
        "    # Collect positives\n",
        "    if cv2.waitKey(1) & 0XFF == ord('p'):\n",
        "        # Create the unique file path \n",
        "        imgname = os.path.join('/content/drive/MyDrive/Colab Notebooks/AlmaBetter Notebooks/Capstone projects/Face Recognition and Drowsiness Detection - Selva Subramanian S/Dataset/Positive', '{}.jpg'.format(uuid.uuid1()))\n",
        "        # Write out positive image\n",
        "        cv2.imwrite(imgname, frame)\n",
        "    \n",
        "    # Show image back to screen\n",
        "    cv2.imshow('Image Collection', frame)\n",
        "    \n",
        "    # Breaking gracefully\n",
        "    if cv2.waitKey(1) & 0XFF == ord('q'):\n",
        "        break\n",
        "        \n",
        "# Release the webcam\n",
        "cap.release()\n",
        "# Close the image show frame\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "FVZUv39Vd0U9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FMwqnnocjrLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bvTTOww5jrO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_7Q3dGIdjrWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RshpEAFod0ZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kzNO2Nncd0dn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zLhh_-0Xd0rd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "buj_F3ypd0vC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6Ya7R0jcd0ya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "73Z0cKxLd1AX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}